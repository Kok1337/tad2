{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4130dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f98203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, data_type=None, transforms=None, size_scale=1):\n",
    "        if data_type is None:\n",
    "            raise Exception(\"You are useless\")\n",
    "        if size_scale <= 0 or size_scale > 1:\n",
    "            raise Exception(\"You are useless\")\n",
    "        self.path = 'data/Food-5K/' + data_type + '/'\n",
    "        self.images_name = os.listdir(self.path)\n",
    "        self.transforms = transforms\n",
    "        self.size_scale = size_scale\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(len(self.images_name) * self.size_scale)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.images_name[idx]\n",
    "        \n",
    "        label = data.split('_')[0]\n",
    "        label = int(label)\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        image = cv2.imread(self.path + data)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            aug = self.transforms(image=image)\n",
    "            image = aug['image']\n",
    "        \n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8dc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformation = A.Compose([\n",
    "                            A.RandomResizedCrop(256, 256),\n",
    "                            A.HorizontalFlip(),\n",
    "                            A.Normalize(),\n",
    "                            ToTensorV2()\n",
    "                        ])\n",
    "train_dataset = FoodDataset('training', image_transformation)\n",
    "val_dataset = FoodDataset('validation', image_transformation)\n",
    "test_dataset = FoodDataset('evaluation', image_transformation)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validloader = DataLoader(val_dataset, batch_size=32)\n",
    "testloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee424029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(average='macro', num_classes=6)\n",
    "        self.recall = torchmetrics.Recall(average='macro', num_classes=6)\n",
    "        self.f1 = torchmetrics.F1Score(average='macro', num_classes=6)\n",
    "        self.precision_metrics = torchmetrics.Precision(average='macro', num_classes=6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.model(x)\n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.008)\n",
    "        return optimizer\n",
    "    \n",
    "    def get_metrics(self, y_pred, y, metrics_type=\"train\"):\n",
    "        predictions = y_pred.argmax(-1)\n",
    "        y = y.type(torch.IntTensor)\n",
    "        \n",
    "        precision = self.precision_metrics(predictions, y)\n",
    "        acc = self.accuracy(predictions, y)\n",
    "        rec = self.recall(predictions, y)\n",
    "        f1 = self.f1(predictions, y)\n",
    "\n",
    "        self.log('acc/test', acc)\n",
    "        self.log('rec/test', rec)\n",
    "        self.log('f1/test', f1)\n",
    "        self.log('prec/test', precision)\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        y_pred = self.forward(x).squeeze()\n",
    "        # y_pred = torch.unsqueeze(y_pred, 0)\n",
    "        loss = self.loss(y_pred, y)\n",
    "        \n",
    "        self.get_metrics(y_pred, y, \"train\")\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "\n",
    "        y_pred = self.forward(x).squeeze()\n",
    "        # y_pred = torch.unsqueeze(y_pred, 0)\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        self.get_metrics(y_pred, y, \"val\")\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        y_pred = self.forward(x).squeeze()\n",
    "        # y_pred = torch.unsqueeze(y_pred, 0)\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        self.get_metrics(y_pred, y, \"test\")\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a804a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(resnet_model, model_name):\n",
    "    gpu = 1 if torch.cuda.is_available() else 0\n",
    "    resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 2)\n",
    "    resnet_model = LitModel(model)\n",
    "    trainer_resnet_model= pl.Trainer(max_epochs=3, gpus=gpu)\n",
    "    trainer_resnet_model.fit(resnet_model, trainloader, validloader)\n",
    "    torch.save(resnet_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c871594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea8cd7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | model             | ResNet           | 42.5 M\n",
      "1 | loss              | CrossEntropyLoss | 0     \n",
      "2 | accuracy          | Accuracy         | 0     \n",
      "3 | recall            | Recall           | 0     \n",
      "4 | f1                | F1Score          | 0     \n",
      "5 | precision_metrics | Precision        | 0     \n",
      "-------------------------------------------------------\n",
      "42.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.5 M    Total params\n",
      "170.017   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe7aa983f5649b29f66202ed250e479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet101(weights='IMAGENET1K_V1')\n",
    "train_model(model, 'resnet101.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0acfe0",
   "metadata": {},
   "source": [
    "### ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f88eccce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c078b6b3c48f4eb5bc1daf30310871a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         acc/test          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3923666775226593     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          f1/test          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44120630621910095    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         prec/test         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5224000215530396     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         rec/test          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3923666775226593     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        acc/test         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3923666775226593    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         f1/test         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44120630621910095   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        prec/test        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5224000215530396    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        rec/test         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3923666775226593    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc/test': 0.3923666775226593,\n",
       "  'rec/test': 0.3923666775226593,\n",
       "  'f1/test': 0.44120630621910095,\n",
       "  'prec/test': 0.5224000215530396}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('resnet101.pth', map_location=torch.device('cpu'))\n",
    "model = LitModel(model)\n",
    "trainer_model = pl.Trainer(max_epochs=20, accelerator='cpu')\n",
    "trainer_model.test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f71ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
